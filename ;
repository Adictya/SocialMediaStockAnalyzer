import re
import json
from typing import List
import nltk

#final series using trie , handle different data sets
#visualization techniques

# nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer

sid = SentimentIntensityAnalyzer()

import praw

import pandas as pd


def get_env_data():
    with open('.env') as f:
        data = json.load(f)
    return data['client-id'], data['client-secret'], data['username'], data[
        'password']


def _get_instance() -> praw.Reddit:
    client_id, client_secret, username, password = get_env_data()
    return praw.Reddit(user_agent='adictya',
                       client_id=client_id,
                       client_secret=client_secret,
                       username=username,
                       password=password)


def _comments_on_submission(submission: praw.models.Submission,
                            replace_lim: int = 0) -> List[str]:
    print(
        f' *\tParsing comments with replace limit={replace_lim} on post: {submission.title}'
    )
    submission.comments.replace_more(limit=replace_lim)
    return submission.comments.list()


def fetchData():
    reddit = _get_instance()
    subreddit = reddit.subreddit('WallStreetBets')

    sid = SentimentIntensityAnalyzer()

    positiveWords = [
        'puts', 'green', 'updoot', 'PINS', 'squeeze', 'moon', 'holy', 'mod',
        'bearish', 'up', 'ðŸš€'
    ]
    negativeWords = [
        'short', 'red', 'downvote', 'hell', 'curse', 'bulish', 'down', 'drop',
        'crash'
    ]

    hot = reddit.submission(id="n9eiyu")

    myDict = {"Author": [], "Comments": [], "Stocks": [], "Sentiment": []}

    # hot = subreddit.hot(limit=1)
    # comments = []
    # df["comment"] = hot.apply(lambda comment: hot)

    # for submission in hot:
    #     myDict["Comments"].append(_comments_on_submission(submission))

    # for comment in _comments_on_submission(hot):
    #     Stocks = re.findall("[A-Z]{1,5}(?:\s*\d{6}[PC]\d{8})?$", comment.body)
    #     if (len(Stocks) > 0):
    #         myDict["Author"].append(comment.author.name)
    #         myDict["Comments"].append(comment.body)
    #         myDict["Stocks"].append(Stocks)
    #         myDict["Sentiment"].append(
    #             sid.polarity_scores(comment.body)["compound"])
    #     # print(comment.body)

    for comment in _comments_on_submission(hot):
        # Stocks = re.findall("[A-Z]{1,5}(?:\s*\d{6}[PC]\d{8})", comment.body)
        Stocks = re.findall("[A-Z]{1,5}(?:\s*\d{6}[PC]\d{8})?$", comment.body)
        if (len(Stocks) > 0):
            myDict["Author"].append(comment.author.name)
            myDict["Comments"].append(comment.body)
            myDict["Stocks"].append(Stocks)
            myDict["Sentiment"].append(
                sid.polarity_scores(comment.body)["compound"])
            for stock in Stocks:
                api.initializeStockData(stock)
                prevClose = api.getPreviousClose(stock)
                currOpen = api.getOpen(stock)
                percentage = ((currOpen - prevClose) / prevClose) * 100
                trustScore = sid.polarity_scores(
                    comment.body)["compound"] * percentage
                trust += trustScore
            myDict["TrustScore"].appen(trust)

    # print(len(comments))
    # print(comments)
    df = pd.DataFrame(myDict)
    df.to_csv('data.csv')


def main():
    fetchData()
    df = pd.read_csv("data.csv")
    df.head()
    print(df)


if __name__ == '__main__':
    main()
